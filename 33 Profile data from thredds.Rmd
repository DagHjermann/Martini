---
title: "Read and plot depth profile data from thredds server"
author: "DHJ"
date: "23 9 2019"
output: 
  github_document:
    html_preview: false
    toc: true

---

# Read and plot depth profile data from thredds server  

What we will do here, is to  
1. Select a NIVA station (here, from some hard-bottom data) and get its coordinates    
2. Get all temperature data from these coordinates  
3. In R, plot those data as a profile plot  
4. Save data on the server, then donload those files to your own computer  

## 1. R part

### a. Libraries
```{r, results='hide', message=FALSE}
library(reticulate)
library(readxl)
library(ggplot2)
library(lubridate)
library(dplyr)
library(purrr)

#
# If you are on your personal computer: add the place where you have installed your Python 
#
if (Sys.getenv("RSTUDIO_USER_IDENTITY") %in% "DHJ"){  # if DHJ has logged on
  # Dag's Python installation
  use_python("C:/WinPython/WPy64-3720/python-3.7.2.amd64/python.exe")
} else {
  # otherwise, we assume we are on Jupyterhub
  use_python("opt/conda/bin/python")
}


```


### b. Get a location for which we want to extract data
* Read hard-bottom data, `data_hardbottom`  
* Then we extract location of the most used stations, `data_loc`  
    - We use count() to get one line per station  
    - count() automatocally adds the variable n for sample size  
    - We then use n to get only stations with >= 500 lines of data  
    
```{r}
data_hardbottom <- read_excel("Test_data/data_hardbottom.xlsx")

data_stations <- data_hardbottom %>%
  count(STATION_CODE, STATION_NAME, LONGITUDE, LATITUDE) %>%
  filter(n > 500)

data_stations

```

### c. Plot stations in leaflet
```{r}
library(leaflet)

leaflet() %>%
  addTiles() %>%
  addMarkers(lng = data_stations$LONGITUDE, 
             lat = data_stations$LATITUDE,
             popup = paste(data_stations$STATION_CODE, data_stations$STATION_NAME))

```

### d. Select one location     
FÃ¦rder fyr  
* Note: this returns a one-row dat frame
```{r}
selected_location <- data_stations %>%
  filter(STATION_CODE == "HT4")

selected_location
```

## 2. Python part

* Python code is put inside code chunks marked 'python' instead of 'R'
* Note that you have to avoid Norwegian letters in the Python code, even in the comments - it causes errors (there is probably a way to fix this)  



### a. Connect to thredds server  
* First, load the packages we need using `import` (similar to `library()` in R)  
* Then we define a 'pointer' called `filehandle`) to the dataset  
* We also create a `grid` object (named `grid`), which will be used in 2h  
```{python}
import numpy as np     # Package for scientific computing 
import pandas as pd    # Package for data frames 
import matplotlib.pyplot as plt   
from datetime import datetime,timedelta

from netCDF4 import Dataset #  This is handy for working with netCDF files

import cartopy.crs as ccrs
import cartopy.feature as cfeature

import roppy

filepath = 'https://thredds.met.no/thredds/dodsC/metusers/arildb/MARTINI800_prov_v2.ncml' # The OPENDAP URL

filehandle = Dataset(filepath) # open for reading 
grid = roppy.SGrid(filehandle) # Create a grid object for our file

```


### b. List all variables  
Lots to choose from!  
```{python}
print(filehandle.variables.keys())

```

### c. Get info on one variable
```{python}
filehandle.variables['P3_Chl']
```

### d. Get all variables' long names  
Note: commented out, as it generates a very long list  
```{python, result = 'hide'}
keys = filehandle.variables.keys()
print('Number of variables:', len(keys))
print()

#
# UNCOMMENT TO SEE THE WHOLE LIST
#
# for key in keys:
#   print(key, '=', filehandle.variables[key].long_name)

```



### e. Access longitude, latitude and time  and dimensions    
* This doesn't actually download the data, it just creates a 'pointer' to them  
```{python}
# Access to the longitude, latitude coordinates

lon = filehandle.variables['lon_rho']
lat = filehandle.variables['lat_rho']
ocean_time = filehandle.variables['ocean_time']

```

### f. Explore dimensions 
```{python}
# Let's see what the dimensions of this variable is by looping over the dimensions
print('Time dimensions:')
for dimension in ocean_time.dimensions:
    # We'll print both dimension name, and the size of th dimension
    print('{}: {}'.format( dimension,  len(filehandle.dimensions[dimension] ) ) )

# And lets look at longitude as well:
print('\nLongitude (or latitude) dimensions:')   # \n is just "line shift"
for dimension in lon.dimensions:
    print( '{}: {}'.format( dimension,  len( filehandle.dimensions[dimension] ) ) )

# And finally let's look at one 'ordinary' variable:
print('\nDimensions of the temperature variable:')
temp = filehandle.variables['temp']
for dimension in temp.dimensions:
    print( '{}: {}'.format( dimension,  len( filehandle.dimensions[dimension] ) ) )

```

### g. Find grid cell closest to our chosen station in R      
* Inside a Python chunk, we can access an R Object (values, vectors, dataframes) by putting `r.` in front of the objects name  
    - E.g., we access R object `selected_location` by `r.selected_location`  
* R data frames are converted to a Pandas DataFrame in Python   
* In a Pandas DataFrame, you access a value by ['column_name'][row_number]  
* Here we will access the R data frame `selected_location` (which has only one line)
* We need to access longitude number 1 and latitude number 1 of this data frame -
but be aware that Python starts counting at zero
* So to get the first Longitude value, we write  
    - R version 1: selected_location[1, 'LONGITUDE'] - OR  
    - R version 2: selected_location$LONGITUDE[1]  
    - Python: r.selected_location['LONGITUDE'][0]  

```{python}
# The decimal degree location of the selected station:
selected_lon = r.selected_location['LONGITUDE'][0]
selected_lat = r.selected_location['LATITUDE'][0]

# We need to find the grid location closest to the selected coordinates.
# For the sake of simplicity, let's calculate the sum of the absolute 
# differences between all grid points latitude and longitude and the 
# selected coordinates. 

position_diff = np.abs( lat[:] - selected_lat ) + np.abs( lon[:] - selected_lon )

# This line will find the indices of the minimum value in 
i, j = np.unravel_index( position_diff.argmin(), position_diff.shape )

print('Grid indices of grid point closest to selected location: {}, {}\n'.format(i, j))
print('Grid point longitude: {}'.format(lon[i,j]))
print('Grid point latitude: {}'.format(lat[i,j]))

```

### h. Depths of depth layers   
* In the Norkyst 800 model, there are 42 depth layers from surface to the bottom, no matter how deep it is  
* Therefore, the actual depth of each depth layer varies  
* From the `grid` object created in 2a, we can get these depths  
* Here, we print the depths at the select location given by i,j   
```{python}

# What type of object is this number? Answer: 'numpy.ma.core.MaskedArray'
# x = grid.z_w[:,i,j]
# print(type(x))

print('Depth of each layer (m):\n')
Z = grid.z_w[: ,i,j]
print(np.round(Z, 2))
# print(np.round(Z, 2))


print('\n\nThickness of each layer (m):\n')
dZ = grid.z_w[1:, i,j] - grid.z_w[:-1, i, j]   # i.e., diffrence between one depth and the next
print(np.round(dZ, 2))

```


### i. Getting values    
* For real applications, we would like to download several or all depths  
* But for demonstration purposes, we will just download the surface value   
* As we saw in part 2f, there are 42 depth levels ('s_rho')  
* ... and 2h showed that depths starts at the bottom, so the first depth (depth = 0) is the bottom and
depth = 41 is the surface (remember, Python starts counting at zero!)
* Also, we pick every 30th day in order to get a quick download  
```{python}
# The dimensions are in (t,z,y,x) order and as indexi,g in Python starts from zero, 
# axis = 1 points to the z-dimension. 

# max of the time dimension
max_time = len(filehandle.dimensions["ocean_time"])

# Pick times (we choose all of them)
times = np.arange(0,max_time,1) 

# temp = potential temperaturen
# salt = salinity
# N1_p = phosphate/phosphorus
# N3_n = nitrate/nitrogen
# chla = chlorophyll A

loc_time = filehandle.variables['ocean_time'][times]
loc_temp = filehandle.variables['temp'][times,:,i,j]

```



## 3. Bring data back to R  

### a. Test plots of the data from Python  
```{r}
# Image plot of matrix (note: axes not given)
image(py$loc_temp)

# Convert time to proper format
time <- as.POSIXct(py$loc_time, origin = "1970-01-01", tz = "UTC")

# Plot time series
plot(time, py$loc_temp[,42], type = "l", col = "red2")  # Top layer
lines(time, py$loc_temp[,1], col = "blue3")             # Bottom layer

```

### b. Checking conversion from matrix to vector  
```{r}
cat("Dimensions:\n")
dim(py$loc_temp)
cat("\nMatrix (part of it):\n")
test <- py$loc_temp[1:5, 1:3]
test
cat("\nMatrix as vector - first 5 entries is column 1, row 1-5 (i.e. depth 1, time 1-5):\n")
as.numeric(test)
```

### c. Convert data to 'long format'  
```{r}
# py$Z = limits of depth layers, from bottom to top (see 2h)
#   I.e., the first two values of py$Z = the bottom and top limits of the bottom layer
# depth_mid = middle depth of each layer (midway between the bottom and top limits)
depth_lo <- head(py$Z,-1)              # all values except the last
depth_hi <- tail(py$Z,-1)              # all values except the first
depth_mid <- (depth_lo + depth_hi)/2   # mid depth

# Make data frame
loc_data <- data.frame(
  Time = time,                                       # time has length 364, but will just repeat itself
  Depth_lo = rep(depth_lo, each = length(time)),     # value no. 1 is repeteated 364 times, etc.
  Depth_hi = rep(depth_hi, each = length(time)),     # value no. 1 is repeteated 364 times, etc.
  Depth_mid = rep(depth_mid, each = length(time)),   # value no. 1 is repeteated 364 times, etc.
  Temp = as.numeric(py$loc_temp)                     # transforming matrix to vector
  )

# Plot time series based on data frame  (same plot as in a)
plot(Temp ~ Time, data = subset(loc_data, Depth_mid == depth_mid[42]), type = "l", col = "red2")  # Top layer
lines(Temp ~ Time, data = subset(loc_data, Depth_mid == depth_mid[1]), col = "blue3")             # Bottom layer
```

### d. Plot as discrete points
```{r}
ggplot(loc_data, aes(x = Time, y = Depth_mid, color = Temp)) +
  geom_point() +
  scale_color_gradient2(low = "blue4", mid = "green", high = "red2", midpoint = 10)
```

### e. Plot as tiles   
Use 'height' to set the height of each tile, oth
```{r}
ggplot(loc_data, aes(x = Time, y = Depth_mid, fill = Temp, height = Depth_hi- Depth_lo)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue4", mid = "green", high = "red2", midpoint = 10)
```


### f. Plot as contours   
```{r}
ggplot(loc_data, aes(x = Time, y = Depth_mid, z = Temp)) +
  geom_contour(binwidth = 4)
```

### g. Tiles + contours   
```{r}
ggplot(loc_data, aes(x = Time, y = Depth_mid, fill = Temp, height = Depth_hi- Depth_lo)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue4", mid = "green", high = "red2", midpoint = 10) +
  geom_contour(aes(z = Temp), binwidth = 2, color = "white")
```

### h. Tiles + contours, smoothed  
Here, using GAM with tensor product smooth (te)  
```{r}
library(mgcv)

pred1 <- gam(Temp ~ te(as.numeric(Time), Depth_mid), data = loc_data) %>% predict()
pred2 <- gam(Temp ~ te(as.numeric(Time), Depth_mid, k = 20), data = loc_data) %>% predict()

loc_data$Temp_gam1 = pred1
loc_data$Temp_gam2 = pred2

ggplot(loc_data, aes(x = Time, y = Depth_mid, fill = Temp_gam1, height = Depth_hi- Depth_lo)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue4", mid = "green", high = "red2", midpoint = 10) +
  geom_contour(aes(z = Temp_gam1), binwidth = 2, color = "white")

ggplot(loc_data, aes(x = Time, y = Depth_mid, fill = Temp_gam2, height = Depth_hi- Depth_lo)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue4", mid = "green", high = "red2", midpoint = 10) +
  geom_contour(aes(z = Temp_gam2), binwidth = 2, color = "white")
```

## 4. Bring plots/data back to your computer  
1. Save plots and/or data (see below)   
2. In JupyterLab (unless you are in RStudio), click the folder symbol on the top left of the screen to open file directory  
3. Mark files and right-click to download  
4. If you have many files, you can use zip() in R. Example:  
    - zip("my_zipfile.zip", c("graph1.png", "graph2.png", "graph3.png"))  

### Plots
```{r}
gg <- ggplot(loc_data, aes(x = Time, y = Depth_mid, fill = Temp_gam2, height = Depth_hi- Depth_lo)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue4", mid = "green", high = "red2", midpoint = 10) +
  geom_contour(aes(z = Temp_gam2), binwidth = 2, color = "white")
ggsave("Figures/33_FÃ¦rder_temp_profile.png", gg)

```

### Data
```{r}
write.csv(loc_data, "Data/33_FÃ¦rder_loc_data.csv")

```


